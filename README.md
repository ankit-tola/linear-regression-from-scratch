Linear Regression: Gradient Descent vs Normal Equation

This project demonstrates how Linear Regression can be implemented in Python using two approaches:

Gradient Descent – iterative optimization.

Normal Equation – analytical closed-form solution.

Both methods are applied to the same dataset, and their results are compared visually.

📌 Features

Implements Linear Regression from scratch (no sklearn.linear_model).

Compares Gradient Descent vs Normal Equation.

Plots the regression lines along with dataset points.

Supports custom learning rate, iterations, and dataset size.

⚙️ Installation

Clone the repo:
